#!/usr/bin/env python3
"""
JavaScriptæ·±åº¦æŒ–æ˜å¼•æ“ - å®Œæ•´ç‰ˆ (Advanced JS Mining Engine)
æ–°å¢ï¼šç†µå€¼æ£€æµ‹ã€å®Œæ•´æ­£åˆ™åº“ã€æ™ºèƒ½å¯†é’¥è¯†åˆ«
"""

import asyncio
import aiohttp
import ssl
import re
import json
import time
import math
from datetime import datetime
from typing import List, Dict, Set, Any
from urllib.parse import urljoin, urlparse
import jsbeautifier
from playwright.async_api import async_playwright
from anti_waf_engine import AntiWAFEngine, StealthHTTPClient

class AdvancedJSMiningEngine:
    def __init__(self, target: str):
        self.target = target.rstrip('/')
        self.discovered_js_files: Set[str] = set()
        self.extracted_endpoints: Set[str] = set()
        self.extracted_paths: Set[str] = set()
        self.high_entropy_strings: List[Dict] = []
        self.results = []
        
        # åWAFå¼•æ“é›†æˆ
        self.anti_waf = AntiWAFEngine()
        
        # å®Œæ•´çš„æ•æ„Ÿä¿¡æ¯æ­£åˆ™åº“
        self.sensitive_patterns = {
            # APIå¯†é’¥å’Œä»¤ç‰Œ (æ›´å…¨é¢)
            "firebase_url": r'https://[a-z0-9-]+\.firebaseio\.com',
            "mailgun_key": r'key-[a-z0-9]{32}',
            "twilio_sid": r'AC[a-f0-9]{32}',
            "sendgrid_key": r'SG\.[a-zA-Z0-9_-]{22}\.[a-zA-Z0-9_-]{43}',
            
            # é€šç”¨APIå¯†é’¥æ¨¡å¼
            "api_key_pattern": r'(api[_-]?key|apikey)["\']?\s*[:=]\s*["\'][a-zA-Z0-9_-]{10,}["\']',
            "secret_key_pattern": r'(secret[_-]?key|secretkey)["\']?\s*[:=]\s*["\'][a-zA-Z0-9_-]{10,}["\']',
            "access_token_pattern": r'(access[_-]?token|accesstoken)["\']?\s*[:=]\s*["\'][a-zA-Z0-9_.-]{10,}["\']',
            
            # æ•°æ®åº“å’ŒæœåŠ¡å™¨
            "database_url": r'(database[_-]?url|db[_-]?url)["\']?\s*[:=]\s*["\'][^"\']+["\']',
            "connection_string": r'(connection[_-]?string)["\']?\s*[:=]\s*["\'][^"\']+["\']',
            "server_url": r'(server[_-]?url|base[_-]?url)["\']?\s*[:=]\s*["\']https?://[^"\']+["\']',
            
            # JWTå’Œè®¤è¯
            "jwt_token": r'eyJ[a-zA-Z0-9_-]*\.[a-zA-Z0-9_-]*\.[a-zA-Z0-9_-]*',
            "bearer_token": r'Bearer\s+[a-zA-Z0-9_-]{20,}',
            
            # å¯†ç å’Œå‡­æ®
            "password_pattern": r'(password|passwd)["\']?\s*[:=]\s*["\'][^"\']{6,}["\']',
            "username_pattern": r'(username|user[_-]?name)["\']?\s*[:=]\s*["\'][^"\']{3,}["\']',
            
            # äº‘æœåŠ¡é…ç½®
            "s3_bucket": r's3://[a-z0-9.-]+',
            "azure_storage": r'https://[a-z0-9]+\.blob\.core\.windows\.net',
            "gcp_storage": r'gs://[a-z0-9.-]+',
        }
        
        # APIç«¯ç‚¹åŒ¹é…ï¼ˆä¸åŸºç¡€ç‰ˆæœ¬ç›¸åŒä½†ä¼˜åŒ–ï¼‰
        self.api_patterns = [
            r'["\'/](api|apis?)["\'/][a-zA-Z0-9/_-]+',
            r'["\'/]v\d+["\'/][a-zA-Z0-9/_-]+',
            r'["\'/](graphql|graph)["\'/]?',
            r'["\'/](admin|dashboard|panel)["\'/][a-zA-Z0-9/_-]*',
            r'["\'/](patient|medical|doctor)["\'/][a-zA-Z0-9/_-]*',
            r'["\'/](auth|login|user)["\'/][a-zA-Z0-9/_-]*',
            r'["\']\/[a-zA-Z][a-zA-Z0-9/_-]{2,}["\']',
        ]
        
    def calculate_entropy(self, string: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²çš„é¦™å†œç†µ"""
        if len(string) == 0:
            return 0
        
        # ç»Ÿè®¡å­—ç¬¦é¢‘ç‡
        char_counts = {}
        for char in string:
            char_counts[char] = char_counts.get(char, 0) + 1
        
        # è®¡ç®—ç†µå€¼
        entropy = 0
        length = len(string)
        for count in char_counts.values():
            probability = count / length
            if probability > 0:
                entropy -= probability * math.log2(probability)
                
        return entropy
    
    def is_high_entropy_string(self, string: str, min_length: int = 20, min_entropy: float = 4.5) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé«˜ç†µå€¼å­—ç¬¦ä¸²ï¼ˆå¯èƒ½æ˜¯å¯†é’¥ï¼‰"""
        # è¿‡æ»¤æ¡ä»¶
        if len(string) < min_length:
            return False
            
        # æ’é™¤æ˜æ˜¾çš„éå¯†é’¥å­—ç¬¦ä¸²
        excluded_patterns = [
            r'^https?://',  # URL
            r'^\d+$',       # çº¯æ•°å­—
            r'^[a-z\s]+$',  # çº¯å°å†™å­—æ¯åŠ ç©ºæ ¼
            r'console\.log', # ä»£ç ç‰‡æ®µ
            r'function\s',   # å‡½æ•°å®šä¹‰
            r'var\s|let\s|const\s',  # å˜é‡å£°æ˜
        ]
        
        for pattern in excluded_patterns:
            if re.search(pattern, string, re.IGNORECASE):
                return False
        
        # è®¡ç®—ç†µå€¼
        entropy = self.calculate_entropy(string)
        return entropy >= min_entropy
    
    def extract_high_entropy_strings(self, content: str, js_url: str) -> List[Dict]:
        """æå–é«˜ç†µå€¼å­—ç¬¦ä¸²"""
        high_entropy_results = []
        
        # å¯»æ‰¾å¯èƒ½çš„å¯†é’¥å­—ç¬¦ä¸²ï¼ˆå¼•å·åŒ…å›´çš„é•¿å­—ç¬¦ä¸²ï¼‰
        string_patterns = [
            r'"([a-zA-Z0-9+/=_-]{20,})"',   # åŒå¼•å·
            r"'([a-zA-Z0-9+/=_-]{20,})'",   # å•å¼•å·
            r'`([a-zA-Z0-9+/=_-]{20,})`',   # åå¼•å·
        ]
        
        for pattern in string_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                candidate_string = match.group(1)
                
                if self.is_high_entropy_string(candidate_string):
                    entropy = self.calculate_entropy(candidate_string)
                    
                    result = {
                        "type": "high_entropy_string",
                        "string": candidate_string,
                        "entropy": entropy,
                        "length": len(candidate_string),
                        "position": match.start(),
                        "js_file": js_url,
                        "context": content[max(0, match.start()-50):match.end()+50]
                    }
                    
                    high_entropy_results.append(result)
                    
        return high_entropy_results
    
    def extract_sensitive_info_advanced(self, content: str, js_url: str) -> List[Dict[str, str]]:
        """é«˜çº§æ•æ„Ÿä¿¡æ¯æå–"""
        sensitive_info = []
        
        for info_type, pattern in self.sensitive_patterns.items():
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                info = {
                    "type": info_type,
                    "pattern": pattern,
                    "match": match.group(0)[:100],  # é™åˆ¶é•¿åº¦
                    "position": match.start(),
                    "js_file": js_url
                }
                sensitive_info.append(info)
                
        return sensitive_info
    
    async def run_advanced_js_mining(self):
        """è¿è¡Œé«˜çº§JavaScriptæŒ–æ˜"""
        print("ğŸ§  é«˜çº§JavaScriptæ·±åº¦æŒ–æ˜å¼•æ“å¯åŠ¨")
        print("=" * 60)
        print(f"ğŸ¯ ç›®æ ‡: {self.target}")
        print("ğŸš€ æ–°å¢åŠŸèƒ½: ç†µå€¼æ£€æµ‹ + å®Œæ•´æ­£åˆ™åº“")
        
        # æ˜¾ç¤ºåWAFé…ç½®
        self.anti_waf.print_stealth_stats()
        print("=" * 60)
        
        start_time = time.time()
        
        # Phase 1: æ”¶é›†JSæ–‡ä»¶ï¼ˆä½¿ç”¨åWAFæŠ€æœ¯ï¼‰
        await self._phase1_stealth_js_collection()
        
        # Phase 2: é«˜çº§å†…å®¹åˆ†æ
        await self._phase2_advanced_analysis()
        
        # Phase 3: ç«¯ç‚¹éªŒè¯
        await self._phase3_stealth_endpoint_validation()
        
        duration = time.time() - start_time
        self._generate_advanced_report(duration)
        
    async def _phase1_stealth_js_collection(self):
        """Phase 1: éšè”½JSæ–‡ä»¶æ”¶é›†"""
        print("\nğŸ•µï¸ Phase 1: éšè”½JSæ–‡ä»¶æ”¶é›†")
        print("-" * 50)
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            # è®¾ç½®éšæœºUser-Agent
            user_agent = self.anti_waf.get_random_user_agent()
            await page.set_extra_http_headers({"User-Agent": user_agent})
            
            js_files = set()
            
            async def handle_response(response):
                url = response.url
                content_type = response.headers.get('content-type', '')
                
                if (url.endswith('.js') or 
                    'javascript' in content_type):
                    js_files.add(url)
                    print(f"   ğŸ“„ å‘ç°JSæ–‡ä»¶: {url}")
                    
            page.on('response', handle_response)
            
            try:
                await page.goto(self.target, wait_until='networkidle', timeout=30000)
                await page.wait_for_timeout(5000)
            except Exception as e:
                print(f"   âš ï¸ æµè§ˆå™¨è®¿é—®é”™è¯¯: {e}")
                
            await browser.close()
            
        self.discovered_js_files.update(js_files)
        print(f"   âœ… æ€»å…±å‘ç° {len(self.discovered_js_files)} ä¸ªJSæ–‡ä»¶")
        
    async def _phase2_advanced_analysis(self):
        """Phase 2: é«˜çº§å†…å®¹åˆ†æ"""
        print("\nğŸ§  Phase 2: é«˜çº§å†…å®¹åˆ†æ (ç†µå€¼æ£€æµ‹)")
        print("-" * 50)
        
        async with StealthHTTPClient() as client:
            for js_url in list(self.discovered_js_files)[:30]:  # é™åˆ¶åˆ†ææ•°é‡
                await self._analyze_js_file_advanced(client, js_url)
                
    async def _analyze_js_file_advanced(self, client: StealthHTTPClient, js_url: str):
        """é«˜çº§JSæ–‡ä»¶åˆ†æ"""
        try:
            print(f"ğŸ”¬ é«˜çº§åˆ†æ: {js_url}")
            
            async with await client.get(js_url) as response:
                if response.status == 200:
                    content = await response.text()
                    
                    # ä»£ç ç¾åŒ–
                    if len(content) > 1000 and '\n' not in content[:1000]:
                        try:
                            content = jsbeautifier.beautify(content)
                        except:
                            pass
                    
                    # 1. åŸºç¡€ç«¯ç‚¹æå–
                    endpoints = self._extract_endpoints(content, js_url)
                    
                    # 2. é«˜çº§æ•æ„Ÿä¿¡æ¯æå–
                    sensitive_info = self.extract_sensitive_info_advanced(content, js_url)
                    
                    # 3. ç†µå€¼æ£€æµ‹ (æ–°åŠŸèƒ½!)
                    high_entropy_strings = self.extract_high_entropy_strings(content, js_url)
                    
                    result = {
                        "js_file": js_url,
                        "size": len(content),
                        "endpoints_found": len(endpoints),
                        "sensitive_info_found": len(sensitive_info),
                        "high_entropy_strings_found": len(high_entropy_strings),
                        "endpoints": list(endpoints)[:10],
                        "sensitive_info": sensitive_info,
                        "high_entropy_strings": high_entropy_strings,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    self.results.append(result)
                    self.extracted_endpoints.update(endpoints)
                    self.high_entropy_strings.extend(high_entropy_strings)
                    
                    if sensitive_info or high_entropy_strings:
                        print(f"   ğŸ¯ æ•æ„Ÿä¿¡æ¯: {len(sensitive_info)}, é«˜ç†µå­—ç¬¦ä¸²: {len(high_entropy_strings)}")
                    
        except Exception as e:
            print(f"   âŒ åˆ†æå¤±è´¥: {e}")
            
    def _extract_endpoints(self, content: str, js_url: str) -> Set[str]:
        """æå–APIç«¯ç‚¹ï¼ˆä¸åŸºç¡€ç‰ˆæœ¬ç›¸åŒï¼‰"""
        endpoints = set()
        
        for pattern in self.api_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                endpoint = match.strip('\'"/')
                if len(endpoint) > 2 and not endpoint.startswith('http'):
                    if endpoint.startswith('/'):
                        full_url = f"{self.target}{endpoint}"
                    else:
                        full_url = f"{self.target}/{endpoint}"
                    endpoints.add(full_url)
                    
        return endpoints
        
    async def _phase3_stealth_endpoint_validation(self):
        """Phase 3: éšè”½ç«¯ç‚¹éªŒè¯"""
        print("\nâœ… Phase 3: éšè”½ç«¯ç‚¹éªŒè¯")
        print("-" * 50)
        
        if not self.extracted_endpoints:
            print("   ğŸ“‹ æ²¡æœ‰å‘ç°ç«¯ç‚¹éœ€è¦éªŒè¯")
            return
            
        async with StealthHTTPClient() as client:
            tasks = []
            for endpoint in list(self.extracted_endpoints)[:20]:  # é™åˆ¶éªŒè¯æ•°é‡
                tasks.append(self._validate_endpoint_stealth(client, endpoint))
                
            await asyncio.gather(*tasks, return_exceptions=True)
            
    async def _validate_endpoint_stealth(self, client: StealthHTTPClient, endpoint: str):
        """éšè”½ç«¯ç‚¹éªŒè¯"""
        try:
            async with await client.get(endpoint, allow_redirects=False) as response:
                if response.status in [200, 201]:
                    print(f"   âœ… å¯è®¿é—®: {endpoint} ({response.status})")
                elif response.status in [401, 403]:
                    print(f"   ğŸ” å—ä¿æŠ¤: {endpoint} ({response.status})")
                    
        except Exception as e:
            pass
            
    def _generate_advanced_report(self, duration: float):
        """ç”Ÿæˆé«˜çº§æŒ–æ˜æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"advanced_js_mining_{timestamp}.json"
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_js_files = len(self.discovered_js_files)
        total_endpoints = len(self.extracted_endpoints)
        total_sensitive = sum(len(r.get("sensitive_info", [])) for r in self.results)
        total_high_entropy = len(self.high_entropy_strings)
        
        # é«˜ç†µå­—ç¬¦ä¸²åˆ†æ
        entropy_analysis = {
            "count": total_high_entropy,
            "avg_entropy": sum(s["entropy"] for s in self.high_entropy_strings) / max(1, total_high_entropy),
            "avg_length": sum(s["length"] for s in self.high_entropy_strings) / max(1, total_high_entropy)
        }
        
        report = {
            "scan_info": {
                "target": self.target,
                "timestamp": datetime.now().isoformat(),
                "duration": duration,
                "engine_version": "Advanced v2.0",
                "anti_waf_enabled": True,
                "js_files_analyzed": total_js_files,
                "endpoints_extracted": total_endpoints,
                "sensitive_info_found": total_sensitive,
                "high_entropy_strings_found": total_high_entropy
            },
            "entropy_analysis": entropy_analysis,
            "discovered_js_files": list(self.discovered_js_files),
            "extracted_endpoints": list(self.extracted_endpoints),
            "high_entropy_strings": self.high_entropy_strings,
            "analysis_results": self.results
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        print(f"\nğŸ§  é«˜çº§JavaScriptæŒ–æ˜å®Œæˆ!")
        print(f"ğŸ“‚ JSæ–‡ä»¶åˆ†æ: {total_js_files}")
        print(f"ğŸ”Œ ç«¯ç‚¹å‘ç°: {total_endpoints}")
        print(f"ğŸ” æ•æ„Ÿä¿¡æ¯: {total_sensitive}")
        print(f"ğŸ¯ é«˜ç†µå­—ç¬¦ä¸²: {total_high_entropy}")
        if total_high_entropy > 0:
            print(f"ğŸ“Š å¹³å‡ç†µå€¼: {entropy_analysis['avg_entropy']:.2f}")
        print(f"â±ï¸ æŒ–æ˜è€—æ—¶: {duration:.2f}ç§’")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {filename}")
        
        if total_high_entropy > 0:
            print(f"\nğŸ”¥ å‘ç°é«˜ç†µå­—ç¬¦ä¸²ï¼ˆå¯èƒ½çš„å¯†é’¥ï¼‰:")
            for s in self.high_entropy_strings[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"   ğŸ¯ ç†µå€¼: {s['entropy']:.2f}, é•¿åº¦: {s['length']}, æ–‡ä»¶: {s['js_file']}")

async def main():
    import sys
    
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python js_mining_engine_advanced.py <target>")
        print("ç¤ºä¾‹: python js_mining_engine_advanced.py https://asanoha-clinic.com")
        return
        
    target = sys.argv[1]
    if not target.startswith(('http://', 'https://')):
        target = 'https://' + target
        
    engine = AdvancedJSMiningEngine(target)
    await engine.run_advanced_js_mining()

if __name__ == "__main__":
    asyncio.run(main()) 