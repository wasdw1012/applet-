import os
import sys
import argparse
import struct
import logging
from datetime import datetime, timezone
from PIL import Image, ImageOps
import numpy as np
from io import BytesIO
import hashlib
import traceback

# Optional: JPEG 2000 support
try:
    import glymur
    HAS_JP2_SUPPORT = True
except ImportError:
    HAS_JP2_SUPPORT = False
    print("Warning: JPEG 2000 support not available (pip install glymur)")


DG2_TAG = 0x75  
BIOMETRIC_INFO_GROUP_TEMPLATE_TAG = 0x7F61  
BIOMETRIC_INFO_TEMPLATE_TAG = 0x7F60  
BIOMETRIC_HEADER_TEMPLATE_TAG = 0xA1  
BIOMETRIC_DATA_BLOCK_TAG = 0x5F2E 

ICAO_HEADER_VERSION_TAG = 0x80
BIOMETRIC_TYPE_TAG = 0x81
BIOMETRIC_SUBTYPE_TAG = 0x82
CREATION_DATE_TIME_TAG = 0x83
VALIDITY_PERIOD_TAG = 0x85
CREATOR_TAG = 0x86
FORMAT_OWNER_TAG = 0x87  
FORMAT_TYPE_TAG = 0x88  


SAMPLE_NUMBER_TAG = 0x02

CBEFF_PATRON_HEADER_VERSION = 0x0101
BIOMETRIC_TYPE_FACIAL_FEATURES = 0x02
BIOMETRIC_SUBTYPE_NO_INFO = 0x00

FORMAT_OWNER_ICAO = 0x0101  
FORMAT_TYPE_FACIAL = 0x0005 

# Facial Record Constants
FACE_IMAGE_TYPE_BASIC = 0x00

# Image Type Constants (严格符合 ISO/IEC 19794-5)
IMAGE_TYPE_JPEG = 0x01
IMAGE_TYPE_JPEG2000 = 0x02  # 标准值为0x02

# Size constraints for compact mode
COMPACT_MIN_SIZE = 7000   
COMPACT_MAX_SIZE = 9000   
COMPACT_TARGET_SIZE = 8000 

# Standard passport photo sizes
PASSPORT_PHOTO_SIZES = [
    (240, 320),   # Minimum size
    (300, 400),   # Small size
    (360, 480),   # Medium size
    (420, 560),   # Standard size
    (480, 640),   # Large size
]


def encode_length(length):

    if length < 0:
        raise ValueError(f"Length cannot be negative: {length}")
    
    if length < 0x80:
        return bytes([length])
    elif length <= 0xFF:
        return bytes([0x81, length])
    elif length <= 0xFFFF:
        return struct.pack('>BH', 0x82, length)  # big-endian
    elif length <= 0xFFFFFF:
        return struct.pack('>BI', 0x83, length)[:-1]  # 3big-endian
    elif length <= 0xFFFFFFFF:
        return struct.pack('>BI', 0x84, length)  # 4big-endian
    else:
        raise ValueError(f"Length too large: {length}")

def encode_tlv(tag, value):

    if not isinstance(tag, int) or tag < 0:
        raise ValueError(f"Invalid tag: {tag}")
    if not isinstance(value, bytes):
        raise TypeError(f"Value must be bytes, got {type(value)}")
    
    if tag > 0xFF:
        tag_bytes = struct.pack('>H', tag)  # big-endian
    else:
        tag_bytes = bytes([tag])
    
    length_bytes = encode_length(len(value))
    
    result = tag_bytes + length_bytes + value
    
    expected_min_size = len(tag_bytes) + 1 + len(value)
    if len(result) < expected_min_size:
        raise ValueError(f"TLV encoding error: result too short")

# --- 辅助函数：日期和有效期编码 ---
def encode_creation_datetime() -> bytes:
    """
    编码7字节的创建日期时间 (YYYYMMDDHHMMSS)。
    """
    now = datetime.now(timezone.utc)
    # >HBBBBB = Big-endian, Unsigned Short (2 bytes for year), 5x Unsigned Char (1 byte each)
    return struct.pack('>HBBBBB', now.year, now.month, now.day, now.hour, now.minute, now.second)

def encode_validity_period(years: int = 10) -> bytes:
    """
    编码8字节的有效期 (StartDate-EndDate)。
    """
    start_dt = datetime.now(timezone.utc)
    end_dt = start_dt.replace(year=start_dt.year + years)
    
    start_bytes = struct.pack('>HBB', start_dt.year, start_dt.month, start_dt.day)
    end_bytes = struct.pack('>HBB', end_dt.year, end_dt.month, end_dt.day)
    
    return start_bytes + end_bytes

# ---------------- Image Processing ----------------

def optimize_image_size(img, target_size=(360, 480)):
    """
    Resize image maintaining aspect ratio
    """
    aspect = img.width / img.height
    
    if aspect > target_size[0] / target_size[1]:
        new_width = target_size[0]
        new_height = int(new_width / aspect)
    else:
        new_height = target_size[1]
        new_width = int(new_height * aspect)
    
    return img.resize((new_width, new_height), Image.Resampling.LANCZOS)

def apply_preprocessing(img):
    """
    Apply preprocessing to improve compression
    """
    img = ImageOps.autocontrast(img, cutoff=2)
    
    from PIL import ImageFilter
    img = img.filter(ImageFilter.UnsharpMask(radius=0.5, percent=50, threshold=0))
    
    return img

def convert_image_to_jpeg_compact(input_path, min_size=COMPACT_MIN_SIZE, max_size=COMPACT_MAX_SIZE):
    """
    Convert image to compact JPEG format
    """
    img = Image.open(input_path)
    
    # 处理透明背景 - 转换为白色背景
    if img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info):
        # 创建白色背景
        background = Image.new('RGB', img.size, (255, 255, 255))
        # 如果是RGBA，直接粘贴
        if img.mode == 'RGBA':
            background.paste(img, mask=img.split()[3])  # 使用alpha通道作为蒙版
        else:
            # 转换后粘贴
            img = img.convert('RGBA')
            background.paste(img, mask=img.split()[3])
        img = background
    elif img.mode not in ['RGB', 'L']:
        img = img.convert('RGB')
    
    img = apply_preprocessing(img)
    
    # JPEG头
    expected_jpeg_header = bytes([0xff,0xd8,0xff,0xe0,0x00,0x10,0x4a,0x46,0x49,0x46])
    
    best_data = None
    best_size_info = None
    
    for photo_size in reversed(PASSPORT_PHOTO_SIZES):
        resized_img = optimize_image_size(img, photo_size)
        
        for quality in range(85, 10, -5):
            buffer = BytesIO()
            resized_img.save(
                buffer, 
                format='JPEG',
                quality=quality,
                optimize=True,
                progressive=False,
                subsampling=2,
            )
            data = buffer.getvalue()
            size = len(data)
            
            # 验JPEG头
            if len(data) >= len(expected_jpeg_header):
                if data[:len(expected_jpeg_header)] != expected_jpeg_header:
                    buffer2 = BytesIO()
                    resized_img.save(
                        buffer2,
                        format='JPEG',
                        quality=quality,
                        optimize=False,
                        progressive=False,
                        subsampling=0,
                    )
                    data2 = buffer2.getvalue()
                    if len(data2) >= len(expected_jpeg_header) and data2[:len(expected_jpeg_header)] == expected_jpeg_header:
                        data = data2
                        size = len(data2)
            
            if min_size <= size <= max_size:
                return data, IMAGE_TYPE_JPEG, resized_img.width, resized_img.height
            
            if size < max_size and (best_data is None or size > len(best_data)):
                if best_data is None or (size > len(best_data) and size < max_size) or (len(best_data) > max_size and size < max_size):
                     best_data = data
                     best_size_info = (resized_img.width, resized_img.height, quality, size)
            elif best_data is None and size > max_size:
                 best_data = data
                 best_size_info = (resized_img.width, resized_img.height, quality, size)

    if best_data:
        w, h, q, s = best_size_info
        return best_data, IMAGE_TYPE_JPEG, w, h
    
    last_resort = optimize_image_size(img, PASSPORT_PHOTO_SIZES[0])
    buffer = BytesIO()
    last_resort.save(buffer, format='JPEG', quality=10, optimize=True, subsampling=2)
    data = buffer.getvalue()
    
    return data, IMAGE_TYPE_JPEG, last_resort.width, last_resort.height

def convert_image_to_jpeg2000_compact(input_path, target_size=COMPACT_TARGET_SIZE):
    """
    Convert image to compact JPEG2000 format
    """
    if not HAS_JP2_SUPPORT:
        raise Exception("JPEG2000 support requires glymur library")
    
    img = Image.open(input_path)
    
    if img.mode not in ['RGB', 'L']:
        img = img.convert('RGB')
    
    img = apply_preprocessing(img)
    
    best_data = None
    best_info = None
    
    for photo_size in reversed(PASSPORT_PHOTO_SIZES):
        resized_img = optimize_image_size(img, photo_size)
        
        uncompressed_size = resized_img.width * resized_img.height * 3
        compression_ratio = uncompressed_size / target_size 
        
        for ratio_adjust in [1.0, 1.2, 1.5, 2.0, 2.5, 3.0, 0.8, 0.6]:
            temp_path = 'temp_compact.jp2'
            
            try:
                jp2 = glymur.Jp2k(temp_path, 'wb')
                jp2[:] = np.array(resized_img)
                current_compression_target = compression_ratio * ratio_adjust
                if current_compression_target <= 0:
                    current_compression_target = 1
                jp2.layer = current_compression_target
                
                size = os.path.getsize(temp_path)
                
                if COMPACT_MIN_SIZE <= size <= COMPACT_MAX_SIZE:
                    with open(temp_path, 'rb') as f:
                        data = f.read()
                    os.remove(temp_path)
                    return data, IMAGE_TYPE_JPEG2000, resized_img.width, resized_img.height
                
                if size < COMPACT_MAX_SIZE:
                    with open(temp_path, 'rb') as f:
                        temp_data = f.read()
                    if best_data is None or size > len(best_data):
                        best_data = temp_data
                        best_info = (resized_img.width, resized_img.height, 
                                   current_compression_target, size)
                elif best_data is None and size > COMPACT_MAX_SIZE:
                    with open(temp_path, 'rb') as f:
                        temp_data = f.read()
                    best_data = temp_data
                    best_info = (resized_img.width, resized_img.height,
                               current_compression_target, size)

            except Exception:
                pass  # 忽略编码错误
            finally:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
    
    if best_data:
        w, h, r, s = best_info
        return best_data, IMAGE_TYPE_JPEG2000, w, h
    
    # 回退到JPEG
    return convert_image_to_jpeg_compact(input_path, COMPACT_MIN_SIZE, COMPACT_MAX_SIZE)

def create_facial_record_header():

    header = b''
    header += b'FAC '  # Format Identifier (4 bytes) -
    header += struct.pack('>I', 0x30313030)  # 就他妈是ASCII "0100
    header += b'\x00\x00\x00\x00'  # Length (placeholder, 4 bytes, big-endian)
    header += struct.pack('>H', 1)  # Number of Facial Images (2 bytes, big-endian)
    return header

def create_facial_information(image_type: int, width: int, height: int) -> bytes:
    """创建头信息和图像信息数据块"""
    
    logging.info("        [5F2E内部] --- 构建大头信息块 (Facial Info) ---")
    feature_points_size = 0
    facial_info = b''
    logging.info("        [5F2E内部]     - 特征点数量")
    facial_info += struct.pack('>H', feature_points_size)
    logging.info("        [5F2E内部]     - 性别")
    facial_info += struct.pack('>B', 0)
    logging.info("        [5F2E内部]     - 眼睛颜色")
    facial_info += struct.pack('>B', 0)
    logging.info("        [5F2E内部]     - 头发颜色")
    facial_info += struct.pack('>B', 0)
    logging.info("        [5F2E内部]     - 特征掩码")
    facial_info += struct.pack('>BBB', 0, 0, 0)
    logging.info("        [5F2E内部]     - 表情")
    facial_info += struct.pack('>H', 0)
    logging.info("        [5F2E内部]     - 姿态角度")
    facial_info += struct.pack('>BBB', 0, 0, 0)
    logging.info("        [5F2E内部]     - 姿态角度不确定性")
    facial_info += struct.pack('>BBB', 0, 0, 0)

    logging.info("        [5F2E内部] --- 构建大头信息块 (Image Info) ---")
    image_info = b''
    logging.info("        [5F2E内部]     - 大头类型")
    image_info += struct.pack('>B', FACE_IMAGE_TYPE_BASIC)
    logging.info("        [5F2E内部]     - 大头数据类型")
    image_info += struct.pack('>B', image_type)
    logging.info("        [5F2E内部]     - 宽度 & 高度")
    image_info += struct.pack('>H', width)
    image_info += struct.pack('>H', height)
    logging.info("        [5F2E内部]     - 颜色空间")
    image_info += struct.pack('>B', 1)
    logging.info("        [5F2E内部]     - 来源类型")
    image_info += struct.pack('>B', 2)
    logging.info("        [5F2E内部]     - 设备类型")
    image_info += struct.pack('>H', 0)
    logging.info("        [5F2E内部]     - 质量")
    image_info += struct.pack('>H', 100)
    
    return facial_info + image_info

def create_biometric_header_template():
    
    # ICAO Header Version
    icao_header_version = encode_tlv(ICAO_HEADER_VERSION_TAG, 
                                   struct.pack('>H', CBEFF_PATRON_HEADER_VERSION))
    
    # Biometric Type
    biometric_type = encode_tlv(BIOMETRIC_TYPE_TAG, 
                               bytes([BIOMETRIC_TYPE_FACIAL_FEATURES]))
    
    # Biometric Subtype
    biometric_subtype = encode_tlv(BIOMETRIC_SUBTYPE_TAG, 
                                  bytes([BIOMETRIC_SUBTYPE_NO_INFO]))
    
    # Creation Date/Time
    now = datetime.now(timezone.utc)
    creation_datetime = encode_tlv(CREATION_DATE_TIME_TAG, encode_datetime(now))
    
    # Validity Period 10年
    validity_period = encode_tlv(VALIDITY_PERIOD_TAG, 
                                encode_validity_period(now, now.replace(year=now.year + 10)))
    
    # Creator
    creator = encode_tlv(CREATOR_TAG, struct.pack('>H', 0x0001))
    
    # Format Owner
    format_owner = encode_tlv(FORMAT_OWNER_TAG, 
                             struct.pack('>H', FORMAT_OWNER_ICAO))
    
    # Format Type
    format_type = encode_tlv(FORMAT_TYPE_TAG, 
                            struct.pack('>H', FORMAT_TYPE_FACIAL))
    
    # 组合元素
    header_content = (icao_header_version + biometric_type + biometric_subtype + 
                     creation_datetime + validity_period + creator +
                     format_owner + format_type)
    
    # 生物特征标头
    return encode_tlv(BIOMETRIC_HEADER_TEMPLATE_TAG, header_content)

################### 核心修正：核心函数：创建CBEFF生物特征头部
# --- 修正后版本 (带详细日志) ---
def create_biometric_header_template() -> bytes:
    """创建CBEFF生物特征头 (A1模板)"""
    logging.info("    [A1内部] -> 构建CBEFF大头子元素")
    
    # 1. 分别创建每一个子元素的TLV对象
    logging.info("      [A1内部] - [80] Patron Header Version")
    version_tlv = encode_tlv(ICAO_HEADER_VERSION_TAG, b'\x01\x01')
    
    logging.info("      [A1内部] - [81] Biometric Type (Face)")
    bio_type_tlv = encode_tlv(BIOMETRIC_TYPE_TAG, bytes([BIOMETRIC_TYPE_FACIAL_FEATURES]))
    
    logging.info("      [A1内部] - [82] Biometric Subtype")
    bio_subtype_tlv = encode_tlv(BIOMETRIC_SUBTYPE_TAG, bytes([BIOMETRIC_SUBTYPE_NO_INFO]))
    
    logging.info("      [A1内部] - [83] Creation Date & Time")
    creation_tlv = encode_tlv(CREATION_DATE_TIME_TAG, encode_creation_datetime())
    
    logging.info("      [A1内部] - [85] Validity Period")
    validity_tlv = encode_tlv(VALIDITY_PERIOD_TAG, encode_validity_period())
    
    logging.info("      [A1内部] - [86] Creator ID")
    creator_tlv = encode_tlv(CREATOR_TAG, b'DG2_Generator_v2')
    
    logging.info("      [A1内部] - [87] Format Owner (ICAO)")
    owner_tlv = encode_tlv(FORMAT_OWNER_TAG, struct.pack('>H', FORMAT_OWNER_ICAO))
    
    logging.info("      [A1内部] - [88] Format Type (Face Image)")
    type_tlv = encode_tlv(FORMAT_TYPE_TAG, struct.pack('>H', FORMAT_TYPE_FACIAL))
    
    header_content = (
        version_tlv + bio_type_tlv + bio_subtype_tlv + creation_tlv + 
        validity_tlv + creator_tlv + owner_tlv + type_tlv
    )
    
    logging.info("    [A1内部] 大头子元素完成")
    return encode_tlv(BIOMETRIC_HEADER_TEMPLATE_TAG, header_content)

def create_biometric_data_block(image_data: bytes, image_type: int, width: int, height: int) -> bytes:
    """创建数据封装5F2ETLV"""
    logging.info("    [5F2E内部] -> 构建ISO19794-5记录")
    
    logging.info("      [5F2E内部] --- 开始构建通用头 (General Header)")
    logging.info("      [5F2E内部]   - 格式标识符FAC")
    info_block = create_facial_information(image_type, width, height)
    
    facial_header_prefix = b'FAC ' + b'0100' 
    logging.info("      [5F2E内部]   - 版本号 ('0100')")
    
    num_images = struct.pack('>H', 1)
    logging.info("      [5F2E内部]   - 人脸图像数量 (1)")
    
    total_record_length = 14 + len(info_block) + len(image_data)
    logging.info(f"      [5F2E内部]   - 总记录长度 ({total_record_length} 字节)")
    
    facial_record = (
        facial_header_prefix +
        struct.pack('>I', total_record_length) +
        num_images +
        info_block +
        image_data
    )
    logging.info("    [5F2E内部] ISO19794-5记录完成")
    return encode_tlv(BIOMETRIC_DATA_BLOCK_TAG, facial_record)

# 修正后版本
def generate_dg2_compact(image_path, output_path, format_preference, min_size, max_size):
    """
    (已优化) 根据明确的尺寸参数生成DG2文件。
    """
    logging.info(f"生成DG2: {os.path.basename(image_path)} -> {output_path}")
    logging.info(f"目标大小: {min_size/1000:.1f}KB - {max_size/1000:.1f}KB")

    # 注意：这里不再有判断 'compact' 或 'normal' 的 if/elif/else 语句

    try:
        if format_preference == 'jpeg2000' or (format_preference == 'auto' and HAS_JP2_SUPPORT):
            try:
                target = (min_size + max_size) // 2
                image_data, image_type, width, height = convert_image_to_jpeg2000_compact(image_path, target)
                format_name = "JPEG2000"
            except Exception:
                image_data, image_type, width, height = convert_image_to_jpeg_compact(image_path, min_size, max_size)
                format_name = "JPEG"
        else:
            image_data, image_type, width, height = convert_image_to_jpeg_compact(image_path, min_size, max_size)
            format_name = "JPEG"
        
        logging.info(f"  压缩: {len(image_data)/1000:.1f}KB {format_name} ({width}x{height})")
        
    except Exception as e:
        logging.error(f"图像处理失败: {e}")
        return False
        
    # 插入调试码 ---
    with open('__DEBUG_source_image.jpg', 'wb') as f:
        f.write(image_data)
    logging.warning("  [调试] 已将压缩后的原始JPEG数据保存到 __DEBUG_source_image.jpg")

    # DG2套嵌
    logging.info("[套嵌] 构建DG2 TLV")
    
    # --- 深入A1内部 ---
    logging.info("  [套嵌] -> 构建 [A1] CBEFF Header...")
    biometric_header_template = create_biometric_header_template()
    logging.info(f"  [套嵌]   - 内部包含8个TLV")
    logging.info(f"  [套嵌] <- [A1] CBEFF Header 完成了 ({len(biometric_header_template)} 字节)")

    # --- 深入5F2E内部 ---
    logging.info("  [套嵌] -> 开始构建 [5F2E] Biometric Data Block...")
    biometric_data_block = create_biometric_data_block(image_data, image_type, width, height)
    logging.info(f"  [套嵌]   - 内部包含ISO 19794-5记录 ")
    logging.info(f"  [套嵌] <- [5F2E] Biometric Data Block 完成了 ({len(biometric_data_block)} 字节)")
    
    # --- 组合7F60 ---
    biometric_info_template_content = biometric_header_template + biometric_data_block
    biometric_info_template = encode_tlv(BIOMETRIC_INFO_TEMPLATE_TAG, biometric_info_template_content)
    logging.info(f"  [套嵌] -> 组合 [A1] 和 [5F2E] -> [{BIOMETRIC_INFO_TEMPLATE_TAG:X}] Biometric Info Template ({len(biometric_info_template)} 字节)")

    # --- 组合7F61 ---
    sample_number = encode_tlv(SAMPLE_NUMBER_TAG, b'\x01')
    biometric_info_group_content = sample_number + biometric_info_template
    biometric_info_group = encode_tlv(BIOMETRIC_INFO_GROUP_TEMPLATE_TAG, biometric_info_group_content)
    logging.info(f"  [套嵌] -> 添加 [02] 组合了 -> [{BIOMETRIC_INFO_GROUP_TEMPLATE_TAG:X}] Biometric Info Group ({len(biometric_info_group)} 字节)")
    
    # --- 最终套嵌75 ---
    dg2 = encode_tlv(DG2_TAG, biometric_info_group)
    logging.info(f"[套嵌] -> 最后套嵌 [{DG2_TAG:X}] DG2 Data Object ({len(dg2)} 字节)")
    logging.info("[套嵌] DG2 完成。")
    
    # 保存DG2
    with open(output_path, 'wb') as f:
        f.write(dg2)
    
    # 计算统计
    overhead = len(dg2) - len(image_data)
    checksum = hashlib.sha256(dg2).hexdigest()
    
    print(f" DG2: {len(dg2)/1000:.1f}KB (开销: {overhead}字节)")
    print(f" SHA256: {checksum}")
    
    # DG2提大头看一下
    extract_success, extracted_path, extracted_size = validate_and_extract_dg2_strict(dg2, output_path.replace('.bin', '_extracted'))
    
    if extract_success:
        size_match = abs(extracted_size - len(image_data)) < 100  # 允许100字节容错
        print(f" 完整性验证: {'通过' if size_match else '存在差异'}")
    
    # 报告
    info_content = f"""DG2生成报告
生成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
源文件: {image_path}
输出: {output_path}
格式: {format_name}
尺寸: {width}x{height}
DG2大小: {len(dg2)} 字节
图像大小: {len(image_data)} 字节
SHA256: {hashlib.sha256(dg2).hexdigest()}
提取验证: {'成功' if extract_success else '失败'}
"""
    
    with open(output_path + ".info", "w", encoding='utf-8') as f:
        f.write(info_content)
    
    print(f" 报告: {output_path}.info")
    return True

# --- 修正后的“严格”验证与提取函数 ---
def validate_and_extract_dg2_strict(dg2_data: bytes, output_prefix="extracted"):
    """
    严格版本
    不允许任何扫描或查找。
    """
    print(f"\n[严格验证] 开始解析DG2...")

    def parse_ber_length(data, offset):
        """辅助函数：解析BER-TLV长度"""
        length = 0
        len_of_len = 0
        if data[offset] < 0x80:
            length = data[offset]
            len_of_len = 1
        else:
            num_len_bytes = data[offset] & 0x7F
            offset += 1
            if num_len_bytes == 0 or offset + num_len_bytes > len(data):
                raise ValueError("无效的BER长度编码")
            for i in range(num_len_bytes):
                length = (length << 8) | data[offset + i]
            len_of_len = 1 + num_len_bytes
        return length, len_of_len

    try:
        # 1. 解析DG2顶层 (Tag 0x75)
        offset = 0
        if dg2_data[offset] != 0x75:
            raise ValueError(f"DG2顶层Tag不是0x75，而是0x{dg2_data[offset]:02X}")
        offset += 1
        
        len_75, len_bytes_75 = parse_ber_length(dg2_data, offset)
        offset += len_bytes_75
        val_75 = dg2_data[offset : offset + len_75]
        if len(val_75) != len_75: raise ValueError("DG2顶层数据长度不匹配")
        print("  [✓] Tag 0x75 (DG2) ... OK")

        # 2. 解析生物信息组模板 (Tag 0x7F61)
        offset = 0
        if val_75[offset:offset+2] != b'\x7F\x61':
            raise ValueError(f"期望Tag 0x7F61，实际为0x{val_75[offset:offset+2].hex().upper()}")
        offset += 2
        
        len_7F61, len_bytes_7F61 = parse_ber_length(val_75, offset)
        offset += len_bytes_7F61
        val_7F61 = val_75[offset : offset + len_7F61]
        if len(val_7F61) != len_7F61: raise ValueError("Tag 7F61数据长度不匹配")
        print("  [✓] Tag 0x7F61 (Biometric Info Group) ... OK")

        # 3. 解析实例数量 (Tag 0x02)
        offset = 0
        if val_7F61[offset] != 0x02:
            raise ValueError(f"期望Tag 0x02，实际为0x{val_7F61[offset]:02X}")
        offset += 1
        if val_7F61[offset] != 0x01: raise ValueError("Tag 0x02长度不为1")
        offset += 1
        if val_7F61[offset] != 0x01: raise ValueError("实例数量不为1")
        offset += 1
        print("  [✓] Tag 0x02 (Number of Instances) ... OK")

        # 4. 解析生物信息模板 (Tag 0x7F60)
        if val_7F61[offset:offset+2] != b'\x7F\x60':
            raise ValueError(f"期望Tag 0x7F60，实际为0x{val_7F61[offset:offset+2].hex().upper()}")
        offset += 2
        
        len_7F60, len_bytes_7F60 = parse_ber_length(val_7F61, offset)
        offset += len_bytes_7F60
        val_7F60 = val_7F61[offset : offset + len_7F60]
        if len(val_7F60) != len_7F60: raise ValueError("Tag 7F60数据长度不匹配")
        print("  [✓] Tag 0x7F60 (Biometric Info Template) ... OK")

        # 5. 在0x7F60内部，解析CBEFF头 (Tag 0xA1)
        offset = 0
        if val_7F60[offset:offset+2] != b'\x00\xA1' and val_7F60[offset] != 0xA1: # 兼容单字节和双字节A1
             tag_len = 1 if val_7F60[offset] == 0xA1 else 2
             if tag_len==1:
                 offset+=1
             else:
                 offset +=2
        else:
             offset = 2 if val_7F60[offset:offset+2] == b'\x00\xA1' else 1
        
        len_A1, len_bytes_A1 = parse_ber_length(val_7F60, offset)
        offset += len_bytes_A1 + len_A1 # 跳过整个A1 TLV
        print("  [✓] Tag 0xA1 (CBEFF Header) ... OK")

        # 6. 继续在0x7F60内部，解析生物数据块 (Tag 0x5F2E)
        if val_7F60[offset:offset+2] != b'\x5F\x2E':
            raise ValueError(f"期望Tag 0x5F2E，实际为0x{val_7F60[offset:offset+2].hex().upper()}")
        offset += 2
        
        len_5F2E, len_bytes_5F2E = parse_ber_length(val_7F60, offset)
        offset += len_bytes_5F2E
        val_5F2E = val_7F60[offset : offset + len_5F2E]
        if len(val_5F2E) != len_5F2E: raise ValueError("Tag 5F2E数据长度不匹配")
        print("  [✓] Tag 0x5F2E (Biometric Data Block) ... OK")

        # 7. --- 开始严格解析ISO 19794-5面部记录 ---
        print("  [验证] ISO 19794-5 记录...")
        offset = 0
        
        # 7.1 验证标识符和版本
        if val_5F2E[offset:offset+4] != b'FAC ':
            raise ValueError("ISO头标识符不是'FAC '")
        offset += 4
        if val_5F2E[offset:offset+4] != b'0100':
            raise ValueError("ISO头版本不是'0100'")
        offset += 4
        print("    [✓] Format Identifier & Version ... OK")
        
        # 7.2 读取并验证总长度
        record_length = struct.unpack('>I', val_5F2E[offset:offset+4])[0]
        offset += 4
        if record_length != len(val_5F2E):
            raise ValueError(f"ISO记录长度不匹配：声明 {record_length}, 实际 {len(val_5F2E)}")
        print("    [✓] Record Length ... OK")
        
        # 7.3 读取图像数量
        num_images = struct.unpack('>H', val_5F2E[offset:offset+2])[0]
        offset += 2
        if num_images != 1: raise ValueError(f"图像数量不为1，而是{num_images}")

        # 7.4 读取并跳过面部信息块和图像信息块
        # (面部信息+特征点+图像信息)
        num_feature_points = struct.unpack('>H', val_5F2E[offset:offset+2])[0]
        offset += 2
        
        facial_info_block_size = 17 # 性别(1)+眼色(1)+发色(1)+特征掩码(3)+表情(2)+姿态(3)+不确定性(3)
        feature_points_block_size = 6 * num_feature_points # 每个特征点6字节
        image_info_block_size = 12
        
        header_and_info_total_size = 14 + 2 + facial_info_block_size + feature_points_block_size + image_info_block_size
        
        image_data_offset = header_and_info_total_size
        image_data = val_5F2E[image_data_offset:]
        
        # 7.5 验证图像数据长度
        expected_image_len = record_length - header_and_info_total_size
        if len(image_data) != expected_image_len:
             raise ValueError(f"图像数据长度不匹配：期望 {expected_image_len}, 实际 {len(image_data)}")
        print("    [✓] Image Data Offset & Length ... OK")

        # 8. 判断图像类型并保存
        if image_data.startswith(b'\xFF\xD8'):
            image_ext = "jpg"
        elif image_data.startswith(b'\x00\x00\x00\x0C\x6A\x50\x20\x20\x0D\x0A\x87\x0A'):
            image_ext = "jp2"
        else:
            image_ext = "dat" # 未知
            print("    [!] 警告: 未知的图像文件头")

        extracted_path = f"{output_prefix}_strict.{image_ext}"
        with open(extracted_path, 'wb') as f:
            f.write(image_data)
        
        print(f"  [✓] 图像提取成功: {extracted_path}")
        print(f"  [✓] 图像大小: {len(image_data)/1000:.1f}KB ({image_ext.upper()})")
        return True, extracted_path, len(image_data)

    except Exception as e:
        print(f"  [✗] 严格验证失败: {e}")
        traceback.print_exc()
        return False, None, 0

def main():
    # --- 1. 定义配置 (解决了 NameError) ---
    SIZE_CONFIGS = {
        'compact': {'min_size': 7000, 'max_size': 9000},
        'normal': {'min_size': 11000, 'max_size': 13000},
        'quality': {'min_size': 20000, 'max_size': 30000},
    }

    # --- Setup logging ---
    logging.basicConfig(level=logging.INFO, format='%(message)s')

    # --- Argument Parsing (no changes here) ---
    parser = argparse.ArgumentParser(
        description="生成DG2文件",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
示例:
    python gen_dg2.py dg2.png                   # 紧凑DG2 (7-9KB左右)
    python gen_dg2.py dg2.png --size normal     # 标准DG2 (11-13KB左右)
    python gen_dg2.py dg2.png --format jpeg2000 # 强制JPEG2000格式
        """
    )
    parser.add_argument('image', help='Input image file path')
    parser.add_argument('--format', choices=['auto', 'jpeg', 'jpeg2000'],
                        default='auto', help='Image format preference')
    parser.add_argument('--size', choices=['compact', 'normal', 'quality'],
                        default='compact', help='Size mode')
    parser.add_argument('--out', default='DG2.bin', help='Output file path')
    args = parser.parse_args()

# --- Input Validation ---
    if not os.path.exists(args.image):
        logging.error(f"文件不存在: {args.image}")
        sys.exit(1)

    # --- Main Logic ---
    logging.info(f"--- 开始生成DG2 ({args.size}模式) ---")
    
    # 2. 从配置中选择参数
    config = SIZE_CONFIGS[args.size]
    
    # 3. 调用改造后的核心函数 (解决了 TypeError)
    success = generate_dg2_compact(
        image_path=args.image,
        output_path=args.out,
        format_preference=args.format,
        min_size=config['min_size'],
        max_size=config['max_size']
    )
    
    # --- Exit ---
    if success:
        logging.info("--- DG2生成成功 ---")
    else:
        logging.error("--- DG2生成失败 ---")
        sys.exit(1)
    
if __name__ == '__main__':
    main()    
    
