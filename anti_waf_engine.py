#!/usr/bin/env python3
"""
åWAFå¼•æ“ (Anti-WAF Engine) - ä¸“ä¸šç‰ˆ
ä¸“é—¨ç»•è¿‡WAFã€CDNã€IPSç­‰å®‰å…¨è®¾å¤‡çš„æ£€æµ‹
é›†æˆä»£ç†æ± æŠ€æœ¯ï¼Œå®ç°åˆ†å¸ƒå¼IPå¯¹æŠ—
ç¤ºä¾‹åŸŸåè¯·æ›¿æ¢å®é™…éƒ¨ç½²åŸŸå
"""

import asyncio
import aiohttp
import ssl
import random
import time
import os
from typing import Dict, List, Optional, Any
from datetime import datetime
from urllib.parse import urlparse
from dataclasses import dataclass
from aiohttp_socks import ProxyConnector

@dataclass
class ProxyStats:
    """ä»£ç†ç»Ÿè®¡ä¿¡æ¯"""
    proxy: str
    success_count: int = 0
    failure_count: int = 0
    total_requests: int = 0
    avg_response_time: float = 0.0
    last_success_time: float = 0.0
    last_failure_time: float = 0.0
    quality_score: float = 1.0  # è´¨é‡è¯„åˆ† 0-1
    
    def success_rate(self) -> float:
        if self.total_requests == 0:
            return 0.0
        return self.success_count / self.total_requests
    
    def update_success(self, response_time: float):
        self.success_count += 1
        self.total_requests += 1
        self.last_success_time = time.time()
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        if self.avg_response_time == 0:
            self.avg_response_time = response_time
        else:
            self.avg_response_time = (self.avg_response_time + response_time) / 2
        self._update_quality_score()
    
    def update_failure(self):
        self.failure_count += 1
        self.total_requests += 1
        self.last_failure_time = time.time()
        self._update_quality_score()
    
    def _update_quality_score(self):
        """æ›´æ–°è´¨é‡è¯„åˆ†"""
        if self.total_requests == 0:
            self.quality_score = 1.0
            return
            
        # åŸºç¡€æˆåŠŸç‡æƒé‡60%
        success_rate = self.success_rate()
        base_score = success_rate * 0.6
        
        # å“åº”æ—¶é—´æƒé‡30% (å“åº”æ—¶é—´è¶ŠçŸ­å¾—åˆ†è¶Šé«˜)
        time_score = max(0, (3.0 - self.avg_response_time) / 3.0) * 0.3
        
        # æœ€è¿‘æˆåŠŸæƒé‡10%
        recent_success = 0.1 if time.time() - self.last_success_time < 300 else 0
        
        self.quality_score = min(1.0, base_score + time_score + recent_success)

class AntiWAFEngine:
    def __init__(self, proxy_file: str = "proxies.txt"):
        # çœŸå®æµè§ˆå™¨User-Agentæ±  (2024-2025æœ€æ–°ç‰ˆæœ¬)
        self.user_agents = [
            # Chrome æµè§ˆå™¨
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36", 
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            
            # Firefox æµè§ˆå™¨
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0",
            "Mozilla/5.0 (X11; Linux x86_64; rv:132.0) Gecko/20100101 Firefox/132.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:131.0) Gecko/20100101 Firefox/131.0",
            
            # Safari æµè§ˆå™¨
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.1 Safari/605.1.15",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Safari/605.1.15",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.6 Safari/605.1.15",
            
            # Edge æµè§ˆå™¨
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0",
            
            # ç§»åŠ¨ç«¯æµè§ˆå™¨
            "Mozilla/5.0 (iPhone; CPU iPhone OS 18_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/604.1",
            "Mozilla/5.0 (iPad; CPU OS 18_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/604.1",
            "Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Mobile Safari/537.36",
            "Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Mobile Safari/537.36"
        ]
        
        # å¥å£®æ€§ä»£ç†æ± ç®¡ç†
        self.proxy_file = proxy_file
        self.proxies = []
        self.proxy_pool = {}  # ä»£ç†è´¨é‡æ±  {proxy: ProxyStats}
        self.active_proxies = []  # å½“å‰å¯ç”¨ä»£ç†
        self.frozen_proxies = {}  # å†·å†»ä»£ç† {proxy: unfreeze_time}
        self.proxy_rotation_index = 0  # è½®æ¢ç´¢å¼•
        self.max_proxy_failures = 3  # æœ€å¤§å¤±è´¥æ¬¡æ•°
        self.freeze_duration = 300  # å†·å†»æ—¶é•¿(ç§’)
        self.health_check_interval = 600  # å¥åº·æ£€æŸ¥é—´éš”(ç§’)
        
        # åŠ è½½ä»£ç†åˆ—è¡¨
        self._load_proxies()
        
        # å¸¸è§çš„HTTPå¤´æ±  (æ··æ·†ç”¨)
        self.common_headers = {
            "Accept": [
                "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
                "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "application/json,text/plain,*/*",
                "*/*"
            ],
            "Accept-Language": [
                "en-US,en;q=0.9",
                "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
                "zh-CN,zh;q=0.9,en;q=0.8",
                "en-GB,en-US;q=0.9,en;q=0.8",
                "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7"
            ],
            "Accept-Encoding": [
                "gzip, deflate, br, zstd",
                "gzip, deflate, br",
                "gzip, deflate",
                "identity"
            ],
            "Connection": [
                "keep-alive",
                "close"
            ],
            "Upgrade-Insecure-Requests": ["1"],
            "Sec-Fetch-Dest": ["document", "empty"],
            "Sec-Fetch-Mode": ["navigate", "cors"],
            "Sec-Fetch-Site": ["none", "same-origin", "cross-site"],
            "Cache-Control": ["no-cache", "max-age=0"],
            "Pragma": ["no-cache"]
        }
        
        # å¯é€‰çš„é¢å¤–å¤´éƒ¨ (è¿›ä¸€æ­¥æ··æ·†)
        self.optional_headers = {
            "X-Requested-With": ["XMLHttpRequest"],
            "X-Forwarded-Proto": ["https"],
            "DNT": ["1"],
            "Sec-GPC": ["1"]
        }
        
    def _load_proxies(self):
        """ä»æ–‡ä»¶åŠ è½½ä»£ç†åˆ—è¡¨"""
        if not os.path.exists(self.proxy_file):
            print(f"âš ï¸  ä»£ç†æ–‡ä»¶ {self.proxy_file} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨ç›´è¿æ¨¡å¼")
            return
            
        try:
            with open(self.proxy_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        # åŸºç¡€ä»£ç†æ ¼å¼éªŒè¯
                        if '://' in line:
                            self.proxies.append(line)
            
            print(f"ğŸ“‹ åŠ è½½ä»£ç†: {len(self.proxies)} ä¸ª")
            
        except Exception as e:
            print(f"âŒ ä»£ç†æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    async def _robust_validate_proxy(self, proxy: str, timeout: int = 15) -> tuple[bool, float]:
        """ä¿®å¤ç‰ˆä»£ç†éªŒè¯ - æ­£ç¡®å¤„ç†HTTPå’ŒSOCKSä»£ç†"""
        start_time = time.time()
        
        # ä¼˜åŒ–æµ‹è¯•URLï¼Œæé«˜æˆåŠŸç‡
        test_urls = [
            "http://httpbin.org/ip",
            "http://ifconfig.me/ip", 
            "http://icanhazip.com",
            "http://ident.me"
        ]
        
        # === ä¿®å¤ï¼šæ­£ç¡®å¤„ç†ä¸åŒä»£ç†ç±»å‹ ===
        is_socks_proxy = proxy.startswith(('socks5://', 'socks4://'))
        
        if is_socks_proxy:
            # SOCKSä»£ç†ï¼šä½¿ç”¨ProxyConnectorå¤„ç†
            connector = ProxyConnector.from_url(proxy, ssl=False)
            use_proxy_param = False  # connectorå·²å¤„ç†ä»£ç†
        else:
            # HTTP/HTTPSä»£ç†ï¼šä½¿ç”¨æ™®é€šconnector + proxyå‚æ•°
            connector = aiohttp.TCPConnector(ssl=False, limit=5)
            use_proxy_param = True   # éœ€è¦åœ¨è¯·æ±‚ä¸­ä¼ å…¥proxyå‚æ•°
        # ==========================================
        
        last_error = None
        
        for i, test_url in enumerate(test_urls):
            try:
                timeout_config = aiohttp.ClientTimeout(
                    total=timeout,
                    connect=8,  # æ”¾å®½è¿æ¥è¶…æ—¶
                    sock_read=timeout
                )
                
                # åˆ›å»ºsession
                async with aiohttp.ClientSession(
                    connector=connector,
                    timeout=timeout_config
                ) as session:
                    # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®ä»£ç†ç±»å‹å†³å®šæ˜¯å¦ä¼ å…¥proxyå‚æ•°
                    if use_proxy_param:
                        # HTTPä»£ç†ï¼šéœ€è¦ä¼ å…¥proxyå‚æ•°
                        response = await session.get(test_url, proxy=proxy)
                    else:
                        # SOCKSä»£ç†ï¼šconnectorå·²å¤„ç†ï¼Œä¸éœ€è¦proxyå‚æ•°  
                        response = await session.get(test_url)
                    
                    async with response:
                        response_time = time.time() - start_time
                        
                        # æ›´å®½æ¾éªŒè¯æ¡ä»¶
                        if response.status in [200, 201, 301, 302] and response_time < 25.0:
                                # ç®€å•éªŒè¯å“åº”å†…å®¹
                                try:
                                    content = await response.text()
                                    # æ›´å®½æ¾çš„å†…å®¹éªŒè¯
                                    if len(content) > 3 or response.status in [301, 302]:  
                                        proxy_type = "SOCKS" if is_socks_proxy else "HTTP"
                                        print(f"âœ… {proxy} ({proxy_type}) | {test_url} | {response_time:.2f}s")
                                        # ç¡®ä¿å…³é—­connectorï¼Œé¿å…èµ„æºæ³„éœ²
                                        await connector.close()
                                        return True, response_time
                                except:
                                    # çŠ¶æ€ç æ­£ç¡®å°±ç®—æˆåŠŸï¼ˆæ›´å®½æ¾ï¼‰
                                    proxy_type = "SOCKS" if is_socks_proxy else "HTTP"
                                    print(f"âœ… {proxy} ({proxy_type}) | {test_url} | {response_time:.2f}s (å†…å®¹è§£æå¤±è´¥ä½†çŠ¶æ€æ­£ç¡®)")
                                    await connector.close()
                                    return True, response_time
                            
            except Exception as e:
                last_error = str(e)
                # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè¯Šæ–­
                if i == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªURLå¤±è´¥æ—¶æ‰“å°ï¼Œé¿å…åˆ·å±
                    proxy_type = "SOCKS" if is_socks_proxy else "HTTP"
                    print(f"âŒ {proxy} ({proxy_type}) | {test_url} | é”™è¯¯: {str(e)[:50]}...")
                continue
        
        # ç¡®ä¿å…³é—­connector
        if connector:
            await connector.close()
            
        # æ‰€æœ‰URLéƒ½å¤±è´¥ï¼Œè®°å½•æœ€åä¸€ä¸ªé”™è¯¯
        proxy_type = "SOCKS" if is_socks_proxy else "HTTP"
        print(f"âŒ {proxy} ({proxy_type}) | å…¨éƒ¨å¤±è´¥ | æœ€åé”™è¯¯: {last_error[:50] if last_error else 'Unknown'}...")
        return False, time.time() - start_time
    
    def _unfreeze_expired_proxies(self):
        """è§£å†»è¿‡æœŸçš„ä»£ç†"""
        current_time = time.time()
        expired_proxies = []
        
        for proxy, unfreeze_time in self.frozen_proxies.items():
            if current_time >= unfreeze_time:
                expired_proxies.append(proxy)
        
        for proxy in expired_proxies:
            del self.frozen_proxies[proxy]
            if proxy in self.proxies and proxy not in self.active_proxies:
                self.active_proxies.append(proxy)
                print(f"ğŸ”„ ä»£ç†è§£å†»: {proxy}")
    
    def _freeze_proxy(self, proxy: str):
        """å†·å†»ä»£ç†"""
        if proxy in self.active_proxies:
            self.active_proxies.remove(proxy)
        
        freeze_until = time.time() + self.freeze_duration
        self.frozen_proxies[proxy] = freeze_until
        print(f"â„ï¸  ä»£ç†å†·å†»: {proxy} (è§£å†»æ—¶é—´: {self.freeze_duration}så)")
    
    async def validate_proxies(self, max_concurrent: int = 15) -> int:
        """å¥å£®æ€§å¹¶å‘ä»£ç†éªŒè¯ - é™ä½å¹¶å‘å‡å°‘ç½‘ç»œæ‹¥å µ"""
        if not self.proxies:
            print("âš ï¸  æ— ä»£ç†å¯éªŒè¯")
            return 0
            
        print(f"ğŸ” å¥å£®æ€§ä»£ç†éªŒè¯å¯åŠ¨: {len(self.proxies)} ä¸ªä»£ç†")
        print(f"ğŸš€ å¹¶å‘éªŒè¯: {max_concurrent} ä¸ªåŒæ—¶æ£€æµ‹ (ä¼˜åŒ–ç½‘ç»œç¨³å®šæ€§)")
        print(f"â±ï¸  æ¯ä¸ªä»£ç†è¶…æ—¶: 15ç§’ï¼Œæœ€å¤šå°è¯•6ä¸ªæµ‹è¯•URL")
        print("ğŸ“Š è¯¦ç»†éªŒè¯æ—¥å¿—:")
        
        # æ¸…ç†å†»ç»“è¿‡æœŸçš„ä»£ç†
        self._unfreeze_expired_proxies()
        
        semaphore = asyncio.Semaphore(max_concurrent)
        validation_results = []
        
        async def validate_with_timing(proxy):
            async with semaphore:
                start_time = time.time()
                is_valid, response_time = await self._robust_validate_proxy(proxy)
                
                if proxy not in self.proxy_pool:
                    self.proxy_pool[proxy] = ProxyStats(proxy=proxy)
                
                if is_valid:
                    self.proxy_pool[proxy].update_success(response_time)
                    if proxy not in self.active_proxies:
                        self.active_proxies.append(proxy)
                    print(f"âœ… {proxy} | {response_time:.2f}s | è´¨é‡:{self.proxy_pool[proxy].quality_score:.2f}")
                else:
                    self.proxy_pool[proxy].update_failure()
                    if proxy in self.active_proxies:
                        self.active_proxies.remove(proxy)
                
                return is_valid, response_time
        
        # å¹¶å‘éªŒè¯æ‰€æœ‰ä»£ç†
        tasks = [validate_with_timing(proxy) for proxy in self.proxies]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        valid_results = [r for r in results if isinstance(r, tuple) and r[0]]
        
        # æŒ‰è´¨é‡è¯„åˆ†æ’åº
        self.active_proxies.sort(key=lambda p: self.proxy_pool[p].quality_score, reverse=True)
        
        print(f"\nğŸ“Š éªŒè¯å®Œæˆ: {len(valid_results)}/{len(self.proxies)} å¯ç”¨")
        
        # è¯¦ç»†ç»Ÿè®¡åˆ†æ
        if len(valid_results) > 0:
            avg_response_time = sum(r[1] for r in valid_results) / len(valid_results)
            best_proxy = self.active_proxies[0] if self.active_proxies else None
            print(f"ğŸ“ˆ å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}s")
            if best_proxy:
                best_stats = self.proxy_pool[best_proxy]
                print(f"ğŸ† æœ€ä½³ä»£ç†: {best_proxy} (è´¨é‡:{best_stats.quality_score:.2f})")
        else:
            print("âš ï¸  ä»£ç†éªŒè¯å…¨éƒ¨å¤±è´¥ï¼å¯èƒ½åŸå› :")
            print("   1. ç½‘ç»œç¯å¢ƒé™åˆ¶ (é˜²ç«å¢™/ISPé˜»æ–­)")
            print("   2. ä»£ç†è´¨é‡é—®é¢˜ (å¤±æ•ˆ/è¿‡è½½)")
            print("   3. ç›®æ ‡æµ‹è¯•URLè¢«å±è”½")
            print("   4. æœ¬åœ°ç½‘ç»œé…ç½®é—®é¢˜")
        
        return len(valid_results)
    
    async def initialize_proxy_pool(self):
        """åˆå§‹åŒ–ä»£ç†æ±  - å¿«é€Ÿä¿®å¤ç‰ˆæœ¬"""
        print("ğŸš€ åˆå§‹åŒ–ä»£ç†æ± ...")
        
        if not self.proxies:
            print("âš ï¸  æ²¡æœ‰ä»£ç†é…ç½®ï¼Œä½¿ç”¨ç›´è¿æ¨¡å¼")
            return
        
        # å¿«é€ŸéªŒè¯ä»£ç†
        await self.validate_proxies()
        
        print(f"âœ… ä»£ç†æ± åˆå§‹åŒ–å®Œæˆ: {len(self.active_proxies)} ä¸ªå¯ç”¨ä»£ç†")
    
    async def quick_diagnostic(self) -> Dict[str, Any]:
        """å¿«é€Ÿè¯Šæ–­ç½‘ç»œå’Œä»£ç†ç¯å¢ƒ"""
        print("\nğŸ”¬ æ‰§è¡Œå¿«é€Ÿè¯Šæ–­...")
        diagnostic = {
            'direct_connection': False,
            'dns_resolution': False,
            'test_urls_accessible': [],
            'proxy_protocols': {'http': 0, 'socks5': 0},
            'geographic_distribution': {}
        }
        
        # æµ‹è¯•ç›´è¿
        try:
            connector = aiohttp.TCPConnector(ssl=False)
            timeout_config = aiohttp.ClientTimeout(total=10)
            async with aiohttp.ClientSession(connector=connector, timeout=timeout_config) as session:
                async with session.get("http://httpbin.org/ip") as response:
                    if response.status == 200:
                        diagnostic['direct_connection'] = True
                        print("âœ… ç›´è¿æµ‹è¯•: æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ç›´è¿æµ‹è¯•: å¤±è´¥ - {str(e)[:50]}...")
        
        # ç»Ÿè®¡ä»£ç†ç±»å‹
        for proxy in self.proxies:
            if proxy.startswith('http://'):
                diagnostic['proxy_protocols']['http'] += 1
            elif proxy.startswith('socks5://'):
                diagnostic['proxy_protocols']['socks5'] += 1
        
        print(f"ğŸ“Š ä»£ç†ç»Ÿè®¡: HTTP {diagnostic['proxy_protocols']['http']} ä¸ª, SOCKS5 {diagnostic['proxy_protocols']['socks5']} ä¸ª")
        
        return diagnostic
    
    def get_smart_proxy(self) -> Optional[str]:
        """æ™ºèƒ½ä»£ç†é€‰æ‹© - åŸºäºè´¨é‡è¯„åˆ†çš„è½®æ¢"""
        self._unfreeze_expired_proxies()
        
        if not self.active_proxies:
            return None
        
        # 80%æ¦‚ç‡é€‰æ‹©é«˜è´¨é‡ä»£ç†ï¼Œ20%æ¦‚ç‡éšæœºé€‰æ‹©
        if random.random() < 0.8 and len(self.active_proxies) > 1:
            # æŒ‰è´¨é‡è¯„åˆ†æƒé‡é€‰æ‹©
            top_proxies = self.active_proxies[:min(5, len(self.active_proxies))]
            weights = [self.proxy_pool[p].quality_score for p in top_proxies]
            return random.choices(top_proxies, weights=weights)[0]
        else:
            # ç®€å•è½®æ¢é€‰æ‹©
            proxy = self.active_proxies[self.proxy_rotation_index % len(self.active_proxies)]
            self.proxy_rotation_index += 1
            return proxy
    
    def get_random_proxy(self) -> Optional[str]:
        """è·å–ä»£ç† - å…¼å®¹æ€§æ–¹æ³•"""
        return self.get_smart_proxy()
    
    def mark_proxy_failed(self, proxy: str):
        """æ™ºèƒ½å¤±è´¥å¤„ç† - è®°å½•å¤±è´¥å¹¶è¯„ä¼°æ˜¯å¦å†·å†»"""
        if not proxy or proxy not in self.proxy_pool:
            return
        
        self.proxy_pool[proxy].update_failure()
        stats = self.proxy_pool[proxy]
        
        # å¤±è´¥æ¡ä»¶åˆ¤æ–­
        should_freeze = False
        
        # æ¡ä»¶1: è¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤š
        if stats.failure_count >= self.max_proxy_failures:
            should_freeze = True
        
        # æ¡ä»¶2: æˆåŠŸç‡è¿‡ä½ä¸”æœ‰è¶³å¤Ÿæ ·æœ¬
        elif stats.total_requests >= 10 and stats.success_rate() < 0.3:
            should_freeze = True
        
        # æ¡ä»¶3: è´¨é‡è¯„åˆ†è¿‡ä½
        elif stats.quality_score < 0.2:
            should_freeze = True
        
        if should_freeze:
            self._freeze_proxy(proxy)
            print(f"ğŸ“‰ ä»£ç†è´¨é‡ä¸‹é™: {proxy} | æˆåŠŸç‡:{stats.success_rate():.1%} | è´¨é‡:{stats.quality_score:.2f}")
        else:
            print(f"âš ï¸  ä»£ç†å¤±è´¥: {proxy} | å¤±è´¥æ¬¡æ•°:{stats.failure_count} | æˆåŠŸç‡:{stats.success_rate():.1%}")
    
    def mark_proxy_success(self, proxy: str, response_time: float):
        """è®°å½•ä»£ç†æˆåŠŸ"""
        if proxy and proxy in self.proxy_pool:
            self.proxy_pool[proxy].update_success(response_time)
    
    def get_proxy_stats(self) -> Dict[str, int]:
        """è·å–å¥å£®æ€§ä»£ç†ç»Ÿè®¡ä¿¡æ¯"""
        high_quality_proxies = [p for p in self.active_proxies if self.proxy_pool.get(p, ProxyStats(p)).quality_score > 0.7]
        
        return {
            'total_proxies': len(self.proxies),
            'active_proxies': len(self.active_proxies),
            'frozen_proxies': len(self.frozen_proxies),
            'high_quality_proxies': len(high_quality_proxies),
            'total_requests': sum(stats.total_requests for stats in self.proxy_pool.values()),
            'total_successes': sum(stats.success_count for stats in self.proxy_pool.values())
        }
    
    def get_detailed_proxy_stats(self) -> List[Dict]:
        """è·å–è¯¦ç»†ä»£ç†ç»Ÿè®¡"""
        stats_list = []
        for proxy in self.active_proxies:
            if proxy in self.proxy_pool:
                stats = self.proxy_pool[proxy]
                stats_list.append({
                    'proxy': proxy,
                    'success_rate': stats.success_rate(),
                    'quality_score': stats.quality_score,
                    'avg_response_time': stats.avg_response_time,
                    'total_requests': stats.total_requests
                })
        
        return sorted(stats_list, key=lambda x: x['quality_score'], reverse=True)

    def get_random_user_agent(self) -> str:
        """è·å–éšæœºUser-Agent"""
        return random.choice(self.user_agents)
        
    def get_random_headers(self, include_optional: bool = True) -> Dict[str, str]:
        """ç”ŸæˆéšæœºHTTPå¤´éƒ¨"""
        headers = {}
        
        # å¿…éœ€çš„å¤´éƒ¨
        headers["User-Agent"] = self.get_random_user_agent()
        
        for header_name, values in self.common_headers.items():
            if random.random() > 0.1:  # 90%æ¦‚ç‡åŒ…å«
                headers[header_name] = random.choice(values)
        
        # å¯é€‰çš„å¤´éƒ¨ (30%æ¦‚ç‡åŒ…å«)
        if include_optional and random.random() > 0.7:
            for header_name, values in self.optional_headers.items():
                if random.random() > 0.5:  # 50%æ¦‚ç‡åŒ…å«
                    headers[header_name] = random.choice(values)
                    
        return headers
        
    async def random_delay(self, min_delay: float = 0.3, max_delay: float = 1.2):
        """éšæœºå»¶è¿Ÿ - æ¨¡æ‹Ÿäººç±»è®¿é—®è¡Œä¸º (çŒ¥çéƒ¨ç½²ï¼šå¢å¤§å»¶è¿ŸèŒƒå›´)"""
        delay = random.uniform(min_delay, max_delay)
        await asyncio.sleep(delay)
        
    def create_stealth_session(self, timeout: int = 30) -> aiohttp.ClientSession:
        """åˆ›å»ºéšè”½çš„HTTPä¼šè¯"""
        connector = aiohttp.TCPConnector(
            ssl=ssl.create_default_context(),
            limit=10,  # é™åˆ¶å¹¶å‘è¿æ¥æ•°
            limit_per_host=3,  # é™åˆ¶æ¯ä¸ªä¸»æœºçš„è¿æ¥æ•°
            ttl_dns_cache=300,  # DNSç¼“å­˜TTL
            use_dns_cache=True
        )
        
        timeout_config = aiohttp.ClientTimeout(total=timeout)
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªåŸºç¡€å¤´éƒ¨ä½œä¸ºé»˜è®¤
        default_headers = self.get_random_headers(include_optional=False)
        
        return aiohttp.ClientSession(
            connector=connector,
            timeout=timeout_config,
            headers=default_headers
        )
        
    async def stealth_request(self, 
                            session: aiohttp.ClientSession,
                            method: str,
                            url: str,
                            use_proxy: bool = True,
                            **kwargs) -> aiohttp.ClientResponse:
        """æ‰§è¡Œéšè”½çš„HTTPè¯·æ±‚ - é›†æˆä»£ç†è½®æ¢"""
        
        # éšæœºå»¶è¿Ÿ
        await self.random_delay()
        
        # ä¸ºæ¯ä¸ªè¯·æ±‚ç”Ÿæˆæ–°çš„å¤´éƒ¨
        request_headers = self.get_random_headers()
        
        # åˆå¹¶ç”¨æˆ·æä¾›çš„å¤´éƒ¨
        if "headers" in kwargs:
            request_headers.update(kwargs["headers"])
            
        kwargs["headers"] = request_headers
        
        # æ·»åŠ éšæœºè¡Œä¸ºæ¨¡å¼
        if random.random() > 0.8:  # 20%æ¦‚ç‡æ·»åŠ Referer
            if "headers" not in kwargs:
                kwargs["headers"] = {}
            kwargs["headers"]["Referer"] = self._generate_fake_referer(url)
        
        # å¥å£®æ€§ä»£ç†è½®æ¢ - æ™ºèƒ½é€‰æ‹©
        proxy = None
        if use_proxy and self.active_proxies:
            proxy = self.get_smart_proxy()
            if proxy:
                kwargs["proxy"] = proxy
        
        # æ‰§è¡Œè¯·æ±‚ï¼Œå¸¦å¥å£®æ€§å¤±è´¥å¤„ç†
        max_retries = 3
        for attempt in range(max_retries):
            try:
                request_start_time = time.time()
                response = await session.request(method, url, **kwargs)
                response_time = time.time() - request_start_time
                
                # è®°å½•æˆåŠŸ
                if proxy:
                    self.mark_proxy_success(proxy, response_time)
                
                return response
                
            except Exception as e:
                # å¦‚æœä½¿ç”¨äº†ä»£ç†ä¸”è¯·æ±‚å¤±è´¥ï¼Œæ ‡è®°ä»£ç†å¤±è´¥
                if proxy:
                    self.mark_proxy_failed(proxy)
                    
                    # å¥å£®æ€§é‡è¯•ç­–ç•¥
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        # å°è¯•ç”¨æ–°çš„é«˜è´¨é‡ä»£ç†é‡è¯•
                        new_proxy = self.get_smart_proxy()
                        if new_proxy and new_proxy != proxy:
                            kwargs["proxy"] = new_proxy
                            proxy = new_proxy
                            continue
                        
                        # å¦‚æœæ²¡æœ‰å…¶ä»–ä»£ç†ï¼Œå°è¯•ç›´è¿
                        if "proxy" in kwargs:
                            del kwargs["proxy"]
                            proxy = None
                            continue
                
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œé‡æ–°æŠ›å‡ºå¼‚å¸¸
                if attempt == max_retries - 1:
                    raise e
        
    def print_stealth_stats(self):
        """æ‰“å°å¥å£®æ€§åWAFå¼•æ“ç»Ÿè®¡"""
        print("ğŸ•µï¸ åWAFå¼•æ“ ä¸“ä¸šç‰ˆ é…ç½®:")
        print(f"   ğŸ“± User-Agentæ± : {len(self.user_agents)} ä¸ª")
        print(f"   ğŸ”€ è¯·æ±‚å¤´å˜åŒ–: {len(self.common_headers)} ç±»")
        print(f"   â±ï¸ éšæœºå»¶è¿Ÿ: 0.1-0.5ç§’")
        print(f"   ğŸ­ æ··æ·†æŠ€æœ¯: å¯ç”¨")
        
        # å¥å£®æ€§ä»£ç†æ± ç»Ÿè®¡
        proxy_stats = self.get_proxy_stats()
        if proxy_stats['total_proxies'] > 0:
            print(f"   ğŸŒ å¥å£®æ€§ä»£ç†æ± :")
            print(f"      æ€»ä»£ç†æ•°: {proxy_stats['total_proxies']} ä¸ª")
            print(f"      æ´»è·ƒä»£ç†: {proxy_stats['active_proxies']} ä¸ª")
            print(f"      å†·å†»ä»£ç†: {proxy_stats['frozen_proxies']} ä¸ª")
            print(f"      é«˜è´¨é‡ä»£ç†: {proxy_stats['high_quality_proxies']} ä¸ª")
            
            if proxy_stats['total_requests'] > 0:
                success_rate = proxy_stats['total_successes'] / proxy_stats['total_requests']
                print(f"      æ€»ä½“æˆåŠŸç‡: {success_rate:.1%}")
                print(f"      æ€»è¯·æ±‚æ•°: {proxy_stats['total_requests']}")
                
            # æ˜¾ç¤ºå‰3ä¸ªæœ€ä½³ä»£ç†
            top_proxies = self.get_detailed_proxy_stats()[:3]
            if top_proxies:
                print(f"      ğŸ† æœ€ä½³ä»£ç†:")
                for i, proxy_info in enumerate(top_proxies, 1):
                    print(f"         {i}. è´¨é‡:{proxy_info['quality_score']:.2f} | "
                          f"æˆåŠŸç‡:{proxy_info['success_rate']:.1%} | "
                          f"å“åº”:{proxy_info['avg_response_time']:.1f}s")
        else:
            print(f"   ğŸŒ ä»£ç†æ¨¡å¼: ç›´è¿ (æœªé…ç½®ä»£ç†æ± )")

# ä¾¿æ·åŒ…è£…ç±» - ç›´æ¥æ›¿æ¢ç°æœ‰HTTPè¯·æ±‚
class StealthHTTPClient:
    def __init__(self, proxy_file: str = "proxies.txt", validate_proxies: bool = False):
        self.anti_waf = AntiWAFEngine(proxy_file)
        self.session = None
        self.validate_proxies = validate_proxies
        
    async def __aenter__(self):
        # å¦‚æœéœ€è¦ï¼ŒéªŒè¯ä»£ç†æ± 
        if self.validate_proxies and self.anti_waf.proxies:
            await self.anti_waf.validate_proxies()
            
        self.session = self.anti_waf.create_stealth_session()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
            
    async def get(self, url: str, **kwargs) -> aiohttp.ClientResponse:
        """éšè”½GETè¯·æ±‚"""
        return await self.anti_waf.stealth_request(self.session, "GET", url, **kwargs)
        
    async def post(self, url: str, **kwargs) -> aiohttp.ClientResponse:
        """éšè”½POSTè¯·æ±‚"""
        return await self.anti_waf.stealth_request(self.session, "POST", url, **kwargs)
        
    async def put(self, url: str, **kwargs) -> aiohttp.ClientResponse:
        """éšè”½PUTè¯·æ±‚"""
        return await self.anti_waf.stealth_request(self.session, "PUT", url, **kwargs)
        
    async def delete(self, url: str, **kwargs) -> aiohttp.ClientResponse:
        """éšè”½DELETEè¯·æ±‚"""
        return await self.anti_waf.stealth_request(self.session, "DELETE", url, **kwargs)
    
    def get_headers(self) -> Dict[str, str]:
        """è·å–éšæœºå¤´éƒ¨ï¼ˆå…¼å®¹ç°æœ‰ä»£ç ï¼‰"""
        return self.anti_waf.get_random_headers()
    
    def get_proxy_stats(self) -> Dict[str, int]:
        """è·å–ä»£ç†ç»Ÿè®¡ä¿¡æ¯"""
        return self.anti_waf.get_proxy_stats()
    
    async def validate_proxies(self) -> int:
        """æ‰‹åŠ¨éªŒè¯ä»£ç†æ± """
        return await self.anti_waf.validate_proxies()
    
    def print_stats(self):
        """æ‰“å°å¼•æ“ç»Ÿè®¡ä¿¡æ¯"""
        self.anti_waf.print_stealth_stats()

# æµ‹è¯•å‡½æ•°
async def test_anti_waf():
    """æµ‹è¯•åWAFå¼•æ“ - åŒ…å«ä»£ç†æ± æµ‹è¯•"""
    print("ğŸ” åWAFå¼•æ“ ä¸“ä¸šç‰ˆ æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•åŸºç¡€åŠŸèƒ½
    anti_waf = AntiWAFEngine()
    anti_waf.print_stealth_stats()
    
    print("\nğŸ§ª æµ‹è¯•User-Agentè½®æ¢:")
    for i in range(3):
        ua = anti_waf.get_random_user_agent()
        print(f"   {i+1}. {ua[:60]}...")
        
    print("\nğŸ§ª æµ‹è¯•éšæœºå¤´éƒ¨ç”Ÿæˆ:")
    for i in range(2):
        headers = anti_waf.get_random_headers()
        print(f"   {i+1}. å¤´éƒ¨æ•°é‡: {len(headers)}")
        print(f"      User-Agent: {headers.get('User-Agent', 'N/A')[:50]}...")
    
    # æµ‹è¯•ä»£ç†æ± åŠŸèƒ½  
    if anti_waf.proxies:
        print("\nğŸŒ æµ‹è¯•ä»£ç†æ± åŠŸèƒ½:")
        print(f"   åŠ è½½ä»£ç†: {len(anti_waf.proxies)} ä¸ª")
        
        # è¿è¡Œå¿«é€Ÿè¯Šæ–­
        await anti_waf.quick_diagnostic()
        
        # éªŒè¯ä»£ç†ï¼ˆé™ä½å¹¶å‘æ•°ä»¥å‡å°‘ç½‘ç»œå‹åŠ›ï¼‰
        if len(anti_waf.proxies) > 0:
            print("\n   å¼€å§‹éªŒè¯ä»£ç†...")
            valid_count = await anti_waf.validate_proxies(max_concurrent=10)
            
            if valid_count > 0:
                print(f"\n   âœ… å‘ç° {valid_count} ä¸ªå¯ç”¨ä»£ç†")
                
                # æ˜¾ç¤ºè¯¦ç»†ä»£ç†ç»Ÿè®¡
                detailed_stats = anti_waf.get_detailed_proxy_stats()
                if detailed_stats:
                    print(f"   ğŸ“‹ ä»£ç†è´¨é‡æŠ¥å‘Š:")
                    for i, stats in enumerate(detailed_stats[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ª
                        print(f"      {i}. {stats['proxy']} | è´¨é‡:{stats['quality_score']:.2f} | å“åº”:{stats['avg_response_time']:.1f}s")
                
                # æµ‹è¯•ä»£ç†è½®æ¢
                print("\nğŸ”„ æµ‹è¯•ä»£ç†è½®æ¢:")
                for i in range(3):
                    proxy = anti_waf.get_smart_proxy()
                    if proxy:
                        print(f"   {i+1}. {proxy}")
                    else:
                        print(f"   {i+1}. æ— å¯ç”¨ä»£ç†")
            else:
                print("\n   âš ï¸  æ²¡æœ‰å‘ç°å¯ç”¨ä»£ç†")
                print("   ğŸ’¡ å»ºè®®:")
                print("      1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®")
                print("      2. å°è¯•æ›´æ¢ä»£ç†æº")
                print("      3. é™ä½å¹¶å‘æ•°é‡è¯•")
    else:
        print("\nğŸŒ ä»£ç†æ± : æœªé…ç½®ï¼Œä½¿ç”¨ç›´è¿æ¨¡å¼")
    
    print("\nâœ… åWAFå¼•æ“æµ‹è¯•å®Œæˆ")

# ç®€åŒ–çš„ä»£ç†æ± æµ‹è¯•
async def test_proxy_pool():
    """ä¸“é—¨æµ‹è¯•ä»£ç†æ± åŠŸèƒ½"""
    print("ğŸŒ ä»£ç†æ± ä¸“é¡¹æµ‹è¯•")
    print("=" * 40)
    
    async with StealthHTTPClient(validate_proxies=True) as client:
        client.print_stats()
        
        # å°è¯•å‘èµ·ä¸€ä¸ªæµ‹è¯•è¯·æ±‚
        try:
            print("\nğŸ” æµ‹è¯•ä»£ç†è¯·æ±‚...")
            async with await client.get("http://httpbin.org/ip") as response:
                if response.status == 200:
                    data = await response.json()
                    print(f"âœ… è¯·æ±‚æˆåŠŸï¼ŒIP: {data.get('origin', 'Unknown')}")
                else:
                    print(f"âš ï¸  è¯·æ±‚è¿”å›çŠ¶æ€ç : {response.status}")
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "proxy":
        asyncio.run(test_proxy_pool())
    else:
        asyncio.run(test_anti_waf()) 