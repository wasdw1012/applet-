import asyncio
import aiohttp
import json
import time
from typing import List, Dict, Any

class S3DeepScanner:
    """S3æ·±åº¦æ‰«æå™¨"""
    
    def __init__(self):
        self.session = None
        self.found_issues = []
    
    async def __aenter__(self):
        connector = aiohttp.TCPConnector(limit=100, ssl=False)
        timeout = aiohttp.ClientTimeout(total=10)
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': 'S3DeepScanner/1.0'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def deep_scan_bucket(self, bucket_name: str):
        """æ·±åº¦æ‰«æå•ä¸ªS3æ¡¶"""
        print(f"  å¼€å§‹æ·±åº¦æ‰«æ: {bucket_name}")
        
        # 1. ç”Ÿæˆå˜ç§æ¡¶å
        variants = self._generate_bucket_variants(bucket_name)
        await self._scan_bucket_variants(bucket_name, variants)
        
        # 2. æµ‹è¯•ä¸åŒçš„è®¿é—®æ–¹å¼
        await self._test_access_methods(bucket_name)
        
        # 3. å°è¯•å¸¸è§æ•æ„Ÿæ–‡ä»¶è·¯å¾„
        await self._scan_sensitive_paths(bucket_name)
        
        # 4. æ£€æµ‹ç‰ˆæœ¬æ§åˆ¶
        await self._check_versioning(bucket_name)
        
        # 5. å°è¯•é”™è¯¯é…ç½®
        await self._test_misconfigurations(bucket_name)
    
    def _generate_bucket_variants(self, base_name: str) -> List[str]:
        """ç”Ÿæˆæ¡¶çš„å˜ç§åç§°"""
        variants = []
        
        # åŸºäºbase_nameç”Ÿæˆæ›´å¤šå¯èƒ½çš„æ¡¶
        patterns = [
            f"{base_name}-backup",
            f"{base_name}-backups", 
            f"{base_name}-data",
            f"{base_name}-files",
            f"{base_name}-logs",
            f"{base_name}-uploads",
            f"{base_name}-temp",
            f"{base_name}-staging",
            f"{base_name}-prod",
            f"{base_name}-production",
            f"{base_name}-dev",
            f"{base_name}-development",
            f"backup-{base_name}",
            f"data-{base_name}",
            f"files-{base_name}",
            f"logs-{base_name}",
            f"{base_name}backup",
            f"{base_name}data",
            f"{base_name}files",
            f"{base_name}logs",
            f"{base_name}2021",
            f"{base_name}2022", 
            f"{base_name}2023",
            f"{base_name}2024",
            f"{base_name}2025",
            f"{base_name}-old",
            f"{base_name}-new",
            f"{base_name}-bak",
            f"{base_name}-copy",
        ]
        
        return patterns
    
    async def _scan_bucket_variants(self, original: str, variants: List[str]):
        """æ‰«ææ¡¶çš„å˜ç§"""
        print(f"  æ‰«æ {len(variants)} ä¸ªå˜ç§æ¡¶...")
        
        tasks = []
        for variant in variants:
            task = self._check_bucket_exists(variant)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        found_variants = []
        for i, result in enumerate(results):
            if isinstance(result, dict) and result.get('exists'):
                found_variants.append(variants[i])
                status = result.get('status', 'unknown')
                print(f"  å‘ç°å˜ç§æ¡¶: {variants[i]} - {status}")
                
                self.found_issues.append({
                    'type': 'variant_bucket_found',
                    'bucket': variants[i],
                    'original': original,
                    'status': status,
                    'severity': 'high' if status == 'public' else 'medium'
                })
        
        return found_variants
    
    async def _check_bucket_exists(self, bucket_name: str) -> Dict[str, Any]:
        """æ£€æŸ¥æ¡¶æ˜¯å¦å­˜åœ¨"""
        endpoints = [
            f"https://{bucket_name}.s3.amazonaws.com",
            f"https://s3.amazonaws.com/{bucket_name}"
        ]
        
        for endpoint in endpoints:
            try:
                async with self.session.head(endpoint) as response:
                    if response.status == 200:
                        return {'exists': True, 'status': 'public', 'url': endpoint}
                    elif response.status == 403:
                        return {'exists': True, 'status': 'private', 'url': endpoint}
                    elif response.status == 404:
                        return {'exists': False}
            except:
                continue
        
        return {'exists': False}
    
    async def _test_access_methods(self, bucket_name: str):
        """æµ‹è¯•ä¸åŒçš„è®¿é—®æ–¹å¼"""
        print(f"ğŸ”“ æµ‹è¯•è®¿é—®æ–¹å¼: {bucket_name}")
        
        # æµ‹è¯•ä¸åŒçš„ç«¯ç‚¹æ ¼å¼
        endpoints = [
            f"https://{bucket_name}.s3.amazonaws.com",
            f"https://s3.amazonaws.com/{bucket_name}",
            f"https://{bucket_name}.s3-us-west-2.amazonaws.com",
            f"https://{bucket_name}.s3-eu-west-1.amazonaws.com",
            f"https://{bucket_name}.s3.ap-southeast-1.amazonaws.com",
            f"http://{bucket_name}.s3.amazonaws.com",  # HTTPè€ŒéHTTPS
        ]
        
        for endpoint in endpoints:
            try:
                async with self.session.get(endpoint) as response:
                    if response.status == 200:
                        content = await response.text()
                        print(f"  å…¬å¼€è®¿é—®æˆåŠŸ: {endpoint}")
                        
                        # è§£æåˆ—è¡¨å†…å®¹
                        files = self._parse_s3_listing(content)
                        
                        self.found_issues.append({
                            'type': 'public_access_found',
                            'bucket': bucket_name,
                            'endpoint': endpoint,
                            'files_count': len(files),
                            'sample_files': files[:5],
                            'severity': 'critical'
                        })
                        
                        return True
            except:
                continue
        
        return False
    
    async def _scan_sensitive_paths(self, bucket_name: str):
        """æ‰«ææ•æ„Ÿæ–‡ä»¶è·¯å¾„"""
        print(f"  æ‰«ææ•æ„Ÿè·¯å¾„: {bucket_name}")
        
        # å¸¸è§çš„æ•æ„Ÿæ–‡ä»¶è·¯å¾„
        sensitive_paths = [
            'database.sql',
            'backup.sql', 
            'dump.sql',
            'config.json',
            'config.xml',
            'settings.json',
            'credentials.json',
            'secret.txt',
            'password.txt',
            'users.csv',
            'patients.csv',
            'medical_records.csv',
            'backup.zip',
            'data.zip',
            'export.zip',
            '.env',
            'wp-config.php',
            'database.php',
            'config.php',
            'admin.txt',
            'readme.txt',
            'test.txt',
            'index.html',
            'error.log',
            'access.log',
            'debug.log',
        ]
        
        base_url = f"https://{bucket_name}.s3.amazonaws.com"
        
        for path in sensitive_paths:
            try:
                url = f"{base_url}/{path}"
                async with self.session.head(url) as response:
                    if response.status == 200:
                        # è·å–æ–‡ä»¶å¤§å°
                        size = response.headers.get('Content-Length', 'unknown')
                        print(f"  æ•æ„Ÿæ–‡ä»¶å¯è®¿é—®: {path} ({size} bytes)")
                        
                        self.found_issues.append({
                            'type': 'sensitive_file_accessible',
                            'bucket': bucket_name,
                            'file': path,
                            'url': url,
                            'size': size,
                            'severity': 'critical'
                        })
            except:
                continue
    
    async def _check_versioning(self, bucket_name: str):
        """æ£€æŸ¥ç‰ˆæœ¬æ§åˆ¶æ³„éœ²"""
        print(f"  æ£€æŸ¥ç‰ˆæœ¬æ§åˆ¶: {bucket_name}")
        
        # å°è¯•è®¿é—®ç‰ˆæœ¬æ§åˆ¶ç«¯ç‚¹
        versioning_urls = [
            f"https://{bucket_name}.s3.amazonaws.com/?versioning",
            f"https://{bucket_name}.s3.amazonaws.com/?versions",
            f"https://s3.amazonaws.com/{bucket_name}?versioning",
        ]
        
        for url in versioning_urls:
            try:
                async with self.session.get(url) as response:
                    if response.status == 200:
                        content = await response.text()
                        if 'Version' in content or 'versioning' in content.lower():
                            print(f"  ç‰ˆæœ¬æ§åˆ¶ä¿¡æ¯æ³„éœ²: {url}")
                            
                            self.found_issues.append({
                                'type': 'versioning_exposed',
                                'bucket': bucket_name,
                                'url': url,
                                'severity': 'medium'
                            })
            except:
                continue
    
    async def _test_misconfigurations(self, bucket_name: str):
        """æµ‹è¯•å¸¸è§é”™è¯¯é…ç½®"""
        print(f"âš™ï¸ æ£€æµ‹é”™è¯¯é…ç½®: {bucket_name}")
        
        # æµ‹è¯•CORSé…ç½®
        cors_url = f"https://{bucket_name}.s3.amazonaws.com"
        try:
            headers = {
                'Origin': 'https://evil.com',
                'Access-Control-Request-Method': 'GET'
            }
            async with self.session.options(cors_url, headers=headers) as response:
                cors_headers = response.headers
                if 'Access-Control-Allow-Origin' in cors_headers:
                    origin = cors_headers['Access-Control-Allow-Origin']
                    if origin == '*' or 'evil.com' in origin:
                        print(f"  CORSé”™è¯¯é…ç½®: {origin}")
                        
                        self.found_issues.append({
                            'type': 'cors_misconfiguration',
                            'bucket': bucket_name,
                            'allowed_origin': origin,
                            'severity': 'high'
                        })
        except:
            pass
        
        # æµ‹è¯•å…¶ä»–HTTPæ–¹æ³•
        methods = ['PUT', 'POST', 'DELETE']
        for method in methods:
            try:
                async with self.session.request(method, cors_url) as response:
                    if response.status not in [403, 405, 501]:
                        print(f"  HTTPæ–¹æ³• {method} å¯ç”¨: {response.status}")
                        
                        self.found_issues.append({
                            'type': 'http_method_allowed',
                            'bucket': bucket_name,
                            'method': method,
                            'status': response.status,
                            'severity': 'high'
                        })
            except:
                continue
    
    def _parse_s3_listing(self, xml_content: str) -> List[str]:
        """è§£æS3åˆ—è¡¨XML"""
        import re
        files = []
        key_pattern = r'<Key>(.*?)</Key>'
        matches = re.findall(key_pattern, xml_content)
        return [match for match in matches if not match.endswith('/')]
    
    def print_summary(self):
        """æ‰“å°æ‰«ææ‘˜è¦"""
        print(f"\n{'='*60}")
        print(f"  S3æ·±åº¦æ‰«æå®Œæˆ")
        print(f"{'='*60}")
        
        if not self.found_issues:
            print("  æœªå‘ç°æ˜æ˜¾çš„å®‰å…¨é—®é¢˜")
            return
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        critical = [i for i in self.found_issues if i['severity'] == 'critical']
        high = [i for i in self.found_issues if i['severity'] == 'high'] 
        medium = [i for i in self.found_issues if i['severity'] == 'medium']
        
        print(f"  å‘ç° {len(self.found_issues)} ä¸ªå®‰å…¨é—®é¢˜:")
        print(f"  ğŸ”´ CRITICAL: {len(critical)}")
        print(f"  ğŸŸ  HIGH: {len(high)}")
        print(f"  ğŸŸ¡ MEDIUM: {len(medium)}")
        
        print(f"\nğŸ“‹ è¯¦ç»†é—®é¢˜:")
        for issue in self.found_issues:
            severity_emoji = {
                'critical': 'ğŸ”´',
                'high': 'ğŸŸ ', 
                'medium': 'ğŸŸ¡'
            }.get(issue['severity'], 'âšª')
            
            print(f"\n{severity_emoji} {issue['type'].upper()}")
            for key, value in issue.items():
                if key not in ['type', 'severity']:
                    print(f"    {key}: {value}")

async def main():
    """ä¸»å‡½æ•°"""
    # æ‰«æä¹‹å‰å‘ç°çš„æ¡¶
    buckets_to_scan = ['biograph', 'test-biograph']
    
    async with S3DeepScanner() as scanner:
        for bucket in buckets_to_scan:
            await scanner.deep_scan_bucket(bucket)
            print()
        
        scanner.print_summary()
        
        # ä¿å­˜ç»“æœ
        if scanner.found_issues:
            report_file = f"s3_deep_scan_results_{int(time.time())}.json"
            with open(report_file, 'w') as f:
                json.dump(scanner.found_issues, f, indent=2)
            print(f"\n  è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

if __name__ == "__main__":
    asyncio.run(main()) 